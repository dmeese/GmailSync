import argparse
import os
import re
import time
from tqdm import tqdm
import google.generativeai as genai

# Import the shared utility function
from gmail_utils import get_secret_from_1password

def setup_api_key(api_key_ref):
    """Loads the Gemini API key from 1Password and configures the service."""
    print("Fetching Gemini API Key from 1Password...")
    api_key = get_secret_from_1password(api_key_ref)
    if not api_key:
        print("Error: Could not fetch Gemini API key from 1Password.")
        return False
    
    try:
        genai.configure(api_key=api_key)
        return True
    except Exception as e:
        print(f"Error configuring Gemini API: {e}")
        return False

def parse_archive_file(filepath):
    """
    Parses the email archive file into a list of individual messages.
    Each item in the list is a dictionary containing the message_id and content.
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        print(f"Error: Input file not found at '{filepath}'")
        return []

    # Split the content by the message delimiter
    messages_raw = re.split(r'--- MESSAGE START ---\n', content)
    
    parsed_messages = []
    for msg_raw in messages_raw:
        if not msg_raw.strip():
            continue
        
        # Extract the Message-ID using a regular expression
        match = re.search(r'Message-ID: ([\w\d]+)', msg_raw)
        message_id = match.group(1) if match else "N/A"
        
        parsed_messages.append({
            "id": message_id,
            "content": msg_raw.strip()
        })
        
    return parsed_messages

def analyze_batch_with_llm(model, user_prompt, message_batch, max_retries=3):
    """
    Sends a batch of emails to the Gemini model for analysis in a single request.
    Includes a retry mechanism with exponential backoff for resilience.
    Returns the model's combined response, formatted with delimiters.
    """
    
    # This is the instruction for the LLM on how to behave and format the output.
    system_instruction = (
        "You are an email analysis assistant. I will provide you with a batch of emails. "
        f"For each email, perform the following analysis based on this instruction: '{user_prompt}'\n\n"
        "Please format your response as a single block of text, with a clear delimiter for each email's analysis. "
        "Do not include any preamble, conclusion, or other conversational text outside of the analysis blocks.\n\n"
        "The required format for each analysis is:\n"
        "--- ANALYSIS FOR MESSAGE-ID: [The Message-ID from the email] ---\n"
        "[Your analysis for this email]\n"
        "--- END ANALYSIS ---\n"
    )

    # Combine all email contents for the main part of the prompt
    emails_content_block = "\n\n".join([msg['content'] for msg in message_batch])
    
    full_prompt = f"{system_instruction}\n\nHere is the batch of emails to analyze:\n\n{emails_content_block}"

    for attempt in range(max_retries):
        try:
            response = model.generate_content(full_prompt)
            return response.text
        except Exception as e:
            print(f"\nAttempt {attempt + 1} of {max_retries} failed for a batch. Error: {e}")
            if attempt + 1 == max_retries:
                # If this was the last attempt, log the final failure
                print("Max retries reached. Logging error for this batch.")
                error_output = [f"--- ANALYSIS FOR MESSAGE-ID: {msg['id']} ---\nError after {max_retries} retries: {e}\n--- END ANALYSIS ---" for msg in message_batch]
                return "\n\n".join(error_output)
            
            # Exponential backoff: wait 5, 10, 20 seconds for subsequent retries...
            wait_time = 5 * (2 ** attempt)
            print(f"Waiting for {wait_time} seconds before retrying...")
            time.sleep(wait_time)
    
    return "" # Should not be reached, but as a fallback

def main():
    """Main function to run the LLM analyzer."""
    parser = argparse.ArgumentParser(description="Analyze an email archive file using an LLM.")
    parser.add_argument(
        '--input-file',
        required=True,
        help="Path to the email archive text file generated by gmail_archiver.py."
    )
    parser.add_argument(
        '--prompt',
        required=True,
        help="The analysis prompt to be sent to the LLM for each email."
    )
    parser.add_argument(
        '--api-key-ref',
        required=True,
        help="The 1Password secret reference for the Gemini API key (e.g., 'op://vault/item/password')."
    )
    parser.add_argument(
        '--output-file',
        required=True,
        help="Name of the output text file to save the analysis results."
    )
    parser.add_argument(
        '--model-name',
        default='gemini-2.0-flash-lite',
        help="The name of the Gemini model to use for analysis."
    )
    args = parser.parse_args()

    print("--- LLM Email Analyzer ---")

    if not setup_api_key(args.api_key_ref):
        return

    messages = parse_archive_file(args.input_file)
    if not messages:
        print("No messages found in the input file. Exiting.")
        return

    print(f"Found {len(messages)} messages to analyze.")
    
    model = genai.GenerativeModel(args.model_name)

    batch_size = 10  # Process 10 emails per API call to stay under limits

    try:
        with open(args.output_file, 'w', encoding='utf-8') as f:
            # Chunk the messages into batches and process each batch
            for i in tqdm(range(0, len(messages), batch_size), desc="Analyzing Email Batches"):
                message_batch = messages[i:i + batch_size]
                
                # Analyze the entire batch in one API call
                batch_analysis_result = analyze_batch_with_llm(model, args.prompt, message_batch)
                
                # Write the combined result for the batch to the file
                f.write(batch_analysis_result)
                f.write("\n\n")  # Add spacing between batch results
                
                # A small delay to be a good citizen to the API, even with batching
                time.sleep(2)
    except Exception as e:
        print(f"\nAn error occurred while writing to the output file: {e}")
        return

    print(f"\n--- Analysis Complete ---")
    print(f"Analysis results have been saved to {args.output_file}")

if __name__ == '__main__':
    main()